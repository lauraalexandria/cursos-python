{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "420576a9",
   "metadata": {},
   "source": [
    "1. Achar um banco de dados para ajudar (Pior que o que eu estou usando tem problema nenhum..)\n",
    "2. Adicionar aqueles códigos que mudam o display de notebooks...\n",
    "\n",
    "#### Em conferindo/limpando:\n",
    "\n",
    "- Fazer a leitura dos dados ( + versão para quando tem formatos malucos);\n",
    "- Detectar os tipos das colunas;\n",
    "- Alterar os tipo das colunas para ficar certo;\n",
    "- Aqueles passos de retirada de colunas igual ao que eu fiz na Sicredi;\n",
    "- Será que eu consigo detectar se alguma observação está com padrão diferente dos demais? por exemplo, uma letra em meio a números ou uma data específica com formatação diferente?\n",
    "\n",
    "\n",
    "#### Nas análises:\n",
    "\n",
    "- Fazer uma espécie de skim mais correto ou describe mais completo (Métricas, número nulos, distribuição);\n",
    "- Olhar a correlação entre uma variável e as demais;\n",
    "- Alguma forma de simplificar a junção de dados;\n",
    "\n",
    "Acho que o mais importante é montar uma função única que receba os dois dataframes, e compare:\n",
    "- o número de linhas;\n",
    "- as colunas que estão diferentes (ás vezes até a ordem pode influenciar algo);\n",
    "- os tipos das colunas que estão diferentes;\n",
    "- quais colunas possuem letras, números, vírgulas, pontos, barras, dois pontos, aspas;\n",
    "- tabela com a quantidade de nulos, mínimo, máximo, variância, número de categorias, período considerado pelas datas, porcentagem de linhas duplicadas e destacar o que estiver mais diferente;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff086f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimpy import skim\n",
    "for column in scr_teste.columns:\n",
    "    if scr_teste[column].dtypes == \"object\":\n",
    "        scr_teste[column] = scr_teste[column].astype(\"category\")\n",
    "for column in scr_teste.filter(like=\"cred_\").columns:\n",
    "    scr_teste[column] = scr_teste[column].astype(np.float32)\n",
    "skim(scr_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9717e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.agg(*[f.sum(x).alias(f'sum_{x}') for x in clicks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7f3d78",
   "metadata": {},
   "source": [
    "# Conferindo/Limpando dados com Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53bfd71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f8189b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Credit.csv\", sep=\";\", encoding=\"latin_1\")\n",
    "\n",
    "# 'ascii','big5','big5hkscs','cp037','cp273','cp424','cp437','cp500','cp720','cp737','cp775','cp850','cp852','cp855',\n",
    "# 'cp856','cp857','cp858','cp860','cp861','cp862','cp863','cp864','cp865','cp866','cp869','cp874','cp875','cp932','cp949',\n",
    "# 'cp950','cp1006','cp1026','cp1125','cp1140','cp1250','cp1251','cp1252','cp1253','cp1254','cp1255','cp1256','cp1257','cp1258',\n",
    "# 'euc_jp','euc_jis_2004','euc_jisx0213','euc_kr','gb2312','gbk','gb18030','hz','iso2022_jp','iso2022_jp_1','iso2022_jp_2',\n",
    "# 'iso2022_jp_2004','iso2022_jp_3','iso2022_jp_ext','iso2022_kr','latin_1','iso8859_2','iso8859_3','iso8859_4','iso8859_5','iso8859_6',\n",
    "# 'iso8859_7','iso8859_8','iso8859_9','iso8859_10','iso8859_11','iso8859_13','iso8859_14','iso8859_15','iso8859_16','johab','koi8_r','koi8_t',\n",
    "# 'koi8_u','kz1048','mac_cyrillic','mac_greek','mac_iceland','mac_latin2','mac_roman','mac_turkish','ptcp154','shift_jis','shift_jis_2004',\n",
    "# 'shift_jisx0213','utf_32','utf_32_be','utf_32_le','utf_16','utf_16_be','utf_16_le','utf_7','utf_8','utf_8_sig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c502c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CHEQUEESPECIAL           object\n",
       "USO_CREDITO               int64\n",
       "HISTORICO_CREDITO        object\n",
       "PROPOSITO                object\n",
       "BALANCO_ATUAL             int64\n",
       "BALANCO_MEDIO_CREDITO    object\n",
       "EMPREGADO                object\n",
       "LOCAL                     int64\n",
       "ESTADOCIVIL              object\n",
       "OUTRASFUNCOES            object\n",
       "RESIDENCIADESDE           int64\n",
       "TIPOSBENS                object\n",
       "IDADE                     int64\n",
       "OUTROSPLANOSPGTO         object\n",
       "RESIDENCIA               object\n",
       "CREDITOSEXISTENTES        int64\n",
       "EMPREGO                  object\n",
       "DEPENDENTES               int64\n",
       "TRABAESTRANGEIRO         object\n",
       "CLASSE                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a27f474b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "995    False\n",
       "996    False\n",
       "997    False\n",
       "998    False\n",
       "999    False\n",
       "Name: RESIDENCIA, Length: 1000, dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column = \"RESIDENCIA\"\n",
    "df[column].str.contains(\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "958f2c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "      <th>data3</th>\n",
       "      <th>num1</th>\n",
       "      <th>num2</th>\n",
       "      <th>num3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>2022/01/01</td>\n",
       "      <td>01/01/2022</td>\n",
       "      <td>01</td>\n",
       "      <td>0,1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>2022/01/01</td>\n",
       "      <td>01/01/2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>20,22</td>\n",
       "      <td>20.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>2022/01/01</td>\n",
       "      <td>01/01/2022</td>\n",
       "      <td>02</td>\n",
       "      <td>0,2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        data1       data2       data3  num1   num2   num3\n",
       "0  2022-01-01  2022/01/01  01/01/2022    01    0,1    0.1\n",
       "1  2022-01-01  2022/01/01  01/01/2022  2022  20,22  20.22\n",
       "2  2022-01-01  2022/01/01  01/01/2022    02    0,2    0.2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"data1\": [\"2022-01-01\", \"2022-01-01\", \"2022-01-01\"],\n",
    "                   \"data2\": [\"2022/01/01\", \"2022/01/01\", \"2022/01/01\"],\n",
    "                   \"data3\": [\"01/01/2022\", \"01/01/2022\", \"01/01/2022\"],\n",
    "                   \"num1\": [\"01\", \"2022\", \"02\"],\n",
    "                   \"num2\": [\"0,1\", \"20,22\", \"0,2\"],\n",
    "                   \"num3\": [\"0.1\", \"20.22\", \"0.2\"]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df247765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns_names</th>\n",
       "      <th>initial_types</th>\n",
       "      <th>initial_n_nulls</th>\n",
       "      <th>final_types</th>\n",
       "      <th>final_n_nulls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data1</th>\n",
       "      <td>data1</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data2</th>\n",
       "      <td>data2</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data3</th>\n",
       "      <td>data3</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num1</th>\n",
       "      <td>num1</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num2</th>\n",
       "      <td>num2</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num3</th>\n",
       "      <td>num3</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      columns_names initial_types  initial_n_nulls     final_types  \\\n",
       "data1         data1        object                0  datetime64[ns]   \n",
       "data2         data2        object                0  datetime64[ns]   \n",
       "data3         data3        object                0  datetime64[ns]   \n",
       "num1           num1        object                0         float64   \n",
       "num2           num2        object                0         float64   \n",
       "num3           num3        object                0         float64   \n",
       "\n",
       "       final_n_nulls  \n",
       "data1              0  \n",
       "data2              0  \n",
       "data3              0  \n",
       "num1               0  \n",
       "num2               0  \n",
       "num3               0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primeiro uma função que caso a coluna numérica/data esteja inicialmente como string seja corretamente tipada\n",
    "# Posso separar as transformações por função, para dessa forma utilizar try catch e até mostrar se alguma coluna deu ruim\n",
    "to_compare = pd.DataFrame({\"columns_names\": df.columns, \n",
    "                           \"initial_types\": df.dtypes, \n",
    "                           \"initial_n_nulls\": df.isnull().sum()})\n",
    "\n",
    "for column in df.select_dtypes(\"object\").columns:\n",
    "    \"\"\" A loop to fix numeric ou date columns that were initiallly assigned as object columns. And shows already if the number \n",
    "        of nulls changed.\n",
    "    \"\"\"\n",
    "    if sum(df[column].str.contains(\"[:alpha:]\")) == 0:\n",
    "        if sum(df[column].str.contains(\"-\")) + sum(df[column].str.contains(\"/\")) != 0:\n",
    "            df[column] = pd.to_datetime(df[column])\n",
    "        else:\n",
    "            if sum(df[column].str.contains(\",\")) != 0:\n",
    "                df[column] = df[column].str.replace(\",\", \".\")\n",
    "            df[column] = df[column].astype(\"float\")\n",
    "            \n",
    "to_compare[\"final_types\"] = df.dtypes\n",
    "to_compare[\"final_n_nulls\"] = df.isnull().sum()\n",
    "to_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c7e940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "599793b6",
   "metadata": {},
   "source": [
    "# Conferindo/Limpando dados com Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83fecc47",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-d84b03b9e7f5>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-d84b03b9e7f5>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    export PYSPARK_SUBMIT_ARGS=\"--master local[2] pyspark-shell\"\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# export PYSPARK_SUBMIT_ARGS=\"--master local[2] pyspark-shell\"\n",
    "\n",
    "# Estou tendo esse erro porque não tenho o java instalado, e meu notebook que nem Ubuntu tem... talvez seja\n",
    "# melhor eu fazer isso usando o notebook do trabalho, viu...\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "            .master('local[*]')\n",
    "            .appName(\"Iniciando com Spark\")\n",
    "            .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2ba3bc",
   "metadata": {},
   "source": [
    "# Análises utilizando Pandas+Seaborn(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380341ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted = pd.melt(df, id_vars=['chave_anonima', \"target\"], value_vars=df.columns....)\n",
    "sns.relplot(data = df_melted, x = \"value\", y = \"target\", kind = \"scatter\", col = \"variable\", col_wrap = 3,\n",
    "            facet_kws = {\"sharey\": False}) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6ab45e",
   "metadata": {},
   "source": [
    "# Análises utilizando Pyspark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
