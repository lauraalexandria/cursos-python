{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "420576a9",
   "metadata": {},
   "source": [
    "1. Achar um banco de dados para ajudar (Pior que o que eu estou usando tem problema nenhum..)\n",
    "2. Adicionar aqueles códigos que mudam o display de notebooks...\n",
    "\n",
    "#### Em conferindo/limpando:\n",
    "\n",
    "- Fazer a leitura dos dados ( + versão para quando tem formatos malucos);\n",
    "- Detectar os tipos das colunas;\n",
    "- Alterar os tipo das colunas para ficar certo;\n",
    "- Aqueles passos de retirada de colunas igual ao que eu fiz na Sicredi;\n",
    "- Será que eu consigo detectar se alguma observação está com padrão diferente dos demais? por exemplo, uma letra em meio a números ou uma data específica com formatação diferente?\n",
    "\n",
    "\n",
    "#### Nas análises:\n",
    "\n",
    "- Fazer uma espécie de skim mais correto ou describe mais completo (Métricas, número nulos, distribuição);\n",
    "- Olhar a correlação entre uma variável e as demais;\n",
    "- Alguma forma de simplificar a junção de dados;\n",
    "\n",
    "Acho que o mais importante é montar uma função única que receba os dois dataframes, e compare:\n",
    "- o número de linhas;\n",
    "- as colunas que estão diferentes (ás vezes até a ordem pode influenciar algo);\n",
    "- os tipos das colunas que estão diferentes;\n",
    "- quais colunas possuem letras, números, vírgulas, pontos, barras, dois pontos, aspas;\n",
    "- tabela com a quantidade de nulos, mínimo, máximo, variância, número de categorias, período considerado pelas datas, porcentagem de linhas duplicadas e destacar o que estiver mais diferente;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff086f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimpy import skim\n",
    "skim(scr_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9717e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.agg(*[f.sum(x).alias(f'sum_{x}') for x in clicks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7f3d78",
   "metadata": {},
   "source": [
    "# Conferindo/Limpando dados com Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53bfd71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "#pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f8189b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/Credit.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mdata/Credit.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, sep\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m;\u001b[39;49m\u001b[39m\"\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlatin_1\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m \u001b[39m# 'ascii','big5','big5hkscs','cp037','cp273','cp424','cp437','cp500','cp720','cp737','cp775','cp850','cp852','cp855',\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# 'cp856','cp857','cp858','cp860','cp861','cp862','cp863','cp864','cp865','cp866','cp869','cp874','cp875','cp932','cp949',\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# 'cp950','cp1006','cp1026','cp1125','cp1140','cp1250','cp1251','cp1252','cp1253','cp1254','cp1255','cp1256','cp1257','cp1258',\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m# 'koi8_u','kz1048','mac_cyrillic','mac_greek','mac_iceland','mac_latin2','mac_roman','mac_turkish','ptcp154','shift_jis','shift_jis_2004',\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# 'shift_jisx0213','utf_32','utf_32_be','utf_32_le','utf_16','utf_16_be','utf_16_le','utf_7','utf_8','utf_8_sig'\u001b[39;00m\n",
      "File \u001b[0;32m~/Projetos/datascience-sicredi-credito/.venv/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Projetos/datascience-sicredi-credito/.venv/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Projetos/datascience-sicredi-credito/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Projetos/datascience-sicredi-credito/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Projetos/datascience-sicredi-credito/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Projetos/datascience-sicredi-credito/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Projetos/datascience-sicredi-credito/.venv/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/Credit.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/Credit.csv\", sep=\";\", encoding=\"latin_1\")\n",
    "\n",
    "# 'ascii','big5','big5hkscs','cp037','cp273','cp424','cp437','cp500','cp720','cp737','cp775','cp850','cp852','cp855',\n",
    "# 'cp856','cp857','cp858','cp860','cp861','cp862','cp863','cp864','cp865','cp866','cp869','cp874','cp875','cp932','cp949',\n",
    "# 'cp950','cp1006','cp1026','cp1125','cp1140','cp1250','cp1251','cp1252','cp1253','cp1254','cp1255','cp1256','cp1257','cp1258',\n",
    "# 'euc_jp','euc_jis_2004','euc_jisx0213','euc_kr','gb2312','gbk','gb18030','hz','iso2022_jp','iso2022_jp_1','iso2022_jp_2',\n",
    "# 'iso2022_jp_2004','iso2022_jp_3','iso2022_jp_ext','iso2022_kr','latin_1','iso8859_2','iso8859_3','iso8859_4','iso8859_5','iso8859_6',\n",
    "# 'iso8859_7','iso8859_8','iso8859_9','iso8859_10','iso8859_11','iso8859_13','iso8859_14','iso8859_15','iso8859_16','johab','koi8_r','koi8_t',\n",
    "# 'koi8_u','kz1048','mac_cyrillic','mac_greek','mac_iceland','mac_latin2','mac_roman','mac_turkish','ptcp154','shift_jis','shift_jis_2004',\n",
    "# 'shift_jisx0213','utf_32','utf_32_be','utf_32_le','utf_16','utf_16_be','utf_16_le','utf_7','utf_8','utf_8_sig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c502c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CHEQUEESPECIAL           object\n",
       "USO_CREDITO               int64\n",
       "HISTORICO_CREDITO        object\n",
       "PROPOSITO                object\n",
       "BALANCO_ATUAL             int64\n",
       "BALANCO_MEDIO_CREDITO    object\n",
       "EMPREGADO                object\n",
       "LOCAL                     int64\n",
       "ESTADOCIVIL              object\n",
       "OUTRASFUNCOES            object\n",
       "RESIDENCIADESDE           int64\n",
       "TIPOSBENS                object\n",
       "IDADE                     int64\n",
       "OUTROSPLANOSPGTO         object\n",
       "RESIDENCIA               object\n",
       "CREDITOSEXISTENTES        int64\n",
       "EMPREGO                  object\n",
       "DEPENDENTES               int64\n",
       "TRABAESTRANGEIRO         object\n",
       "CLASSE                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929d4aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirma todos os tipos presentes nos dados!\n",
    "df.dtypes.to_frame(\"type\").groupby(\"type\").value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "958f2c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "      <th>data3</th>\n",
       "      <th>num1</th>\n",
       "      <th>num2</th>\n",
       "      <th>num3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>2022/01/01</td>\n",
       "      <td>01/01/2022</td>\n",
       "      <td>01</td>\n",
       "      <td>0,1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>2022/01/01</td>\n",
       "      <td>01/01/2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>20,22</td>\n",
       "      <td>20.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>2022/01/01</td>\n",
       "      <td>01/01/2022</td>\n",
       "      <td>02</td>\n",
       "      <td>0,2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        data1       data2       data3  num1   num2   num3\n",
       "0  2022-01-01  2022/01/01  01/01/2022    01    0,1    0.1\n",
       "1  2022-01-01  2022/01/01  01/01/2022  2022  20,22  20.22\n",
       "2  2022-01-01  2022/01/01  01/01/2022    02    0,2    0.2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"data1\": [\"2022-01-01\", \"2022-01-01\", \"2022-01-01\"],\n",
    "                   \"data2\": [\"2022/01/01\", \"2022/01/01\", \"2022/01/01\"],\n",
    "                   \"data3\": [\"01/01/2022\", \"01/01/2022\", \"01/01/2022\"],\n",
    "                   \"num1\": [\"01\", \"2022\", \"02\"],\n",
    "                   \"num2\": [\"0,1\", \"20,22\", \"0,2\"],\n",
    "                   \"num3\": [\"0.1\", \"20.22\", \"0.2\"]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df247765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns_names</th>\n",
       "      <th>initial_types</th>\n",
       "      <th>initial_n_nulls</th>\n",
       "      <th>final_types</th>\n",
       "      <th>final_n_nulls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data1</th>\n",
       "      <td>data1</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data2</th>\n",
       "      <td>data2</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data3</th>\n",
       "      <td>data3</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num1</th>\n",
       "      <td>num1</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num2</th>\n",
       "      <td>num2</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num3</th>\n",
       "      <td>num3</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      columns_names initial_types  initial_n_nulls     final_types  \\\n",
       "data1         data1        object                0  datetime64[ns]   \n",
       "data2         data2        object                0  datetime64[ns]   \n",
       "data3         data3        object                0  datetime64[ns]   \n",
       "num1           num1        object                0         float64   \n",
       "num2           num2        object                0         float64   \n",
       "num3           num3        object                0         float64   \n",
       "\n",
       "       final_n_nulls  \n",
       "data1              0  \n",
       "data2              0  \n",
       "data3              0  \n",
       "num1               0  \n",
       "num2               0  \n",
       "num3               0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primeiro uma função que caso a coluna numérica/data esteja inicialmente como string seja corretamente tipada\n",
    "# Posso separar as transformações por função, para dessa forma utilizar try catch e até mostrar se alguma coluna deu ruim\n",
    "to_compare = pd.DataFrame({\"columns_names\": df.columns, \n",
    "                           \"initial_types\": df.dtypes, \n",
    "                           \"initial_n_nulls\": df.isnull().sum()})\n",
    "\n",
    "for column in df.select_dtypes(\"object\").columns:\n",
    "    \"\"\" A loop to fix numeric ou date columns that were initiallly assigned as object columns. And shows already if the number \n",
    "        of nulls changed.\n",
    "    \"\"\"\n",
    "    if sum(df[column].str.contains(\"[:alpha:]\")) == 0:\n",
    "        if sum(df[column].str.contains(\"-\")) + sum(df[column].str.contains(\"/\")) != 0:\n",
    "            df[column] = pd.to_datetime(df[column])\n",
    "        else:\n",
    "            if sum(df[column].str.contains(\",\")) != 0:\n",
    "                df[column] = df[column].str.replace(\",\", \".\")\n",
    "            df[column] = df[column].astype(\"float\")\n",
    "            \n",
    "to_compare[\"final_types\"] = df.dtypes\n",
    "to_compare[\"final_n_nulls\"] = df.isnull().sum()\n",
    "to_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c7e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Existem outros conjuntos de tipos que rgeralmente devem ser trocados? Tipo inicialmente numérico que era para ser data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80d4a00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num1</th>\n",
       "      <th>num2</th>\n",
       "      <th>num3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>675.000000</td>\n",
       "      <td>6.840000</td>\n",
       "      <td>6.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1166.536326</td>\n",
       "      <td>11.587528</td>\n",
       "      <td>11.587528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1012.000000</td>\n",
       "      <td>10.210000</td>\n",
       "      <td>10.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2022.000000</td>\n",
       "      <td>20.220000</td>\n",
       "      <td>20.220000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              num1       num2       num3\n",
       "count     3.000000   3.000000   3.000000\n",
       "mean    675.000000   6.840000   6.840000\n",
       "std    1166.536326  11.587528  11.587528\n",
       "min       1.000000   0.100000   0.100000\n",
       "25%       1.500000   0.150000   0.150000\n",
       "50%       2.000000   0.200000   0.200000\n",
       "75%    1012.000000  10.210000  10.210000\n",
       "max    2022.000000  20.220000  20.220000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2cb6a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "      <th>data3</th>\n",
       "      <th>num1</th>\n",
       "      <th>num2</th>\n",
       "      <th>num3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>2022/01/01</td>\n",
       "      <td>01/01/2022</td>\n",
       "      <td>01</td>\n",
       "      <td>0,1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             data1       data2       data3 num1 num2 num3\n",
       "count            3           3           3    3    3    3\n",
       "unique           1           1           1    3    3    3\n",
       "top     2022-01-01  2022/01/01  01/01/2022   01  0,1  0.1\n",
       "freq             3           3           3    1    1    1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(\"object\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b82b29fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_125059/3976170989.py:1: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  df.select_dtypes(\"datetime\").describe()\n",
      "/tmp/ipykernel_125059/3976170989.py:1: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  df.select_dtypes(\"datetime\").describe()\n",
      "/tmp/ipykernel_125059/3976170989.py:1: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  df.select_dtypes(\"datetime\").describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "      <th>data3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      data1                data2                data3\n",
       "count                     3                    3                    3\n",
       "unique                    1                    1                    1\n",
       "top     2022-01-01 00:00:00  2022-01-01 00:00:00  2022-01-01 00:00:00\n",
       "freq                      3                    3                    3\n",
       "first   2022-01-01 00:00:00  2022-01-01 00:00:00  2022-01-01 00:00:00\n",
       "last    2022-01-01 00:00:00  2022-01-01 00:00:00  2022-01-01 00:00:00"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(\"datetime\").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599793b6",
   "metadata": {},
   "source": [
    "# Conferindo/Limpando dados com Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83fecc47",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-d84b03b9e7f5>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-d84b03b9e7f5>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    export PYSPARK_SUBMIT_ARGS=\"--master local[2] pyspark-shell\"\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# export PYSPARK_SUBMIT_ARGS=\"--master local[2] pyspark-shell\"\n",
    "\n",
    "# Estou tendo esse erro porque não tenho o java instalado, e meu notebook que nem Ubuntu tem... talvez seja\n",
    "# melhor eu fazer isso usando o notebook do trabalho, viu...\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "            .master('local[*]')\n",
    "            .appName(\"Iniciando com Spark\")\n",
    "            .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2ba3bc",
   "metadata": {},
   "source": [
    "# Análises utilizando Pandas+Seaborn(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959e090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficos de Barras para as Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3352a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas para as Numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c7f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots para Comparar Target Numérico e Variáveis Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91d199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Correlação para Comparar Target Numérico e Variáveis Numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39c5d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de Barras Empilhadas para Target Categórico e Variáveis Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d4c558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots para Comparar Target Categórico e Variáveis Numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96471565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comportamento das Variáveis pelo tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380341ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted = pd.melt(df, id_vars=['chave_anonima', \"target\"], value_vars=df.columns....)\n",
    "sns.relplot(data = df_melted, x = \"value\", y = \"target\", kind = \"scatter\", col = \"variable\", col_wrap = 3,\n",
    "            facet_kws = {\"sharey\": False}) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6ab45e",
   "metadata": {},
   "source": [
    "# Análises utilizando Pyspark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ce5d0b99ffa0aba10a32dd509ea7d3c713687e44e85980ba9135a99e504cb411"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
